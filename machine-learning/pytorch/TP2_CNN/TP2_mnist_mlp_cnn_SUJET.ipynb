{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CCXlYGXgf5H"
      },
      "source": [
        "# Réseaux neuronaux convolutifs, Convolutional Neural Networks, CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqV63MLygf5a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# %matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxQa5eLVDXfR"
      },
      "source": [
        "# Introduction : faire une convolution 2-d de base sur Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "328hMMFagPbf"
      },
      "source": [
        "Télécharger et ouvrir une image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZEGWL3DgQBN"
      },
      "source": [
        "!wget -q https://www.irit.fr/~Thomas.Pellegrini/ens/M2RFA/mire.png\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqxRPcx-iXrV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "6ef70bfe-5f3f-4a2a-d3d7-707c0f1b5649"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "img = Image.open(\"mire.png\")\n",
        "img\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=431x262 at 0x7F3501290FD0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C04rUNY92GM0"
      },
      "source": [
        "Transformer l'image object de type PIL en un tensor pytorch. Quelles sont les dimensions de ce tenseur ? Expliquer chacune des dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdTqIIsSiXaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2980ef0-b991-42b7-e53b-e32ef60b4a68"
      },
      "source": [
        "transform = transforms.ToTensor()\n",
        "x = transform(img)\n",
        "x.size()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 262, 431])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n89eMYTM2lAa"
      },
      "source": [
        "Prendre la moyenne du tenseur sur la dimension des canaux, en utilisant ```torch.mean()``` ou bien ```x.mean()```. \n",
        "\n",
        "Remarque : l'option ```keepdim=True``` permet de garder le nombre de dimensions intact.\n",
        "\n",
        "Utiliser la fonction `unsqueeze` ou `unsqueeze_` pour obtenir un tenseur à 4 dimensions :\n",
        "\n",
        "B=1 x C=1 x W x H"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67ITGaXm2P4Z"
      },
      "source": [
        "x = ???\n",
        "\n",
        "x.size(), type(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBN22BCR3YGM"
      },
      "source": [
        "Réaliser une convolution 2d sur le tenseur avec un filtre (un \"kernel\") de taille `3 x 3` qui détecte les bords verticaux. Le kernel doit contenir les valeurs suivantes (cf cours) : \n",
        "\n",
        "  \\begin{pmatrix}\n",
        "  -1 & 0 & 1 \\\\\n",
        "  -1 & 0 & 1 \\\\\n",
        "  -1 & 0 & 1 \\\\\n",
        "  \\end{pmatrix}\n",
        "\n",
        "\n",
        "Pour cela utiliser la fonction `conv2d` de `torch.nn.functional`, *i.e.* `F.conv2d` :\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html\n",
        "\n",
        "__Attention aux dimensions attendues pour ce kernel ! Bien lire la doc__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YxoSSajjbgE"
      },
      "source": [
        "filtre = torch.tensor(???, dtype=torch.float32)\n",
        "print(filtre.size())\n",
        "out = F.conv2d(??)\n",
        "out.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlvYeDv_4Qly"
      },
      "source": [
        "Si votre résultat s'appelle par exemple out, vous pouvez l'afficher sous forme d'image ainsi :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PGjQOCgnII3"
      },
      "source": [
        "im = transforms.ToPILImage()(out.squeeze(0)) \n",
        "display(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCWBHzMS40iS"
      },
      "source": [
        "Réfaire l'opération de convolution mais cette fois-ci pour détecter les bords __horizontaux__. \n",
        "\n",
        "Vous pouvez utiliser l'opérateur `permute()`, qui prend toutes les dimensions du tenseur en argument (ici le tenseur du filtre) pour les échanger.\n",
        "\n",
        "Exemple : \n",
        "\n",
        "Soit un tenseur `t` de dimension 10x30x5.\n",
        "\n",
        "Pour inverser la première et la dernière dimension, il faut faire : `t = t.permute(2,1,0)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwWuwOmr403d"
      },
      "source": [
        "filtre2 = ??\n",
        "out = F.conv2d(??)\n",
        "im = transforms.ToPILImage()(out.squeeze(0)) \n",
        "display(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp2p_yeFgf5d"
      },
      "source": [
        "# Partie II : CNN et MLP sur MNIST\n",
        "\n",
        "## Data : MNIST\n",
        "\n",
        "\n",
        "Le jeu de données MNIST contient des chiffres manuscrits (numériques) en noir et blanc, de taille 28x28 pixels.\n",
        "\n",
        "Nous n'utiliserons que les 2500 premières images : 2000 pour le train et les 500 suivantes en validation.\n",
        "\n",
        "La première fois que cette cell est utilisée, MNIST est téléchargé."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URrXse7rgf5e"
      },
      "source": [
        "mnist_train = datasets.MNIST('data',\n",
        "                             train=True,\n",
        "                             download=True,\n",
        "                             transform=transforms.ToTensor())\n",
        "mnist_train = list(mnist_train)[:2500]\n",
        "\n",
        "mnist_train, mnist_val = mnist_train[:2000], mnist_train[2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX2SoHengf5f"
      },
      "source": [
        "## Modèles\n",
        "\n",
        "Nous allons travailler avec deux modèles : un MLP et un réseau neuronal convolutif (CNN).\n",
        "\n",
        "\n",
        "Pour définir un réseau il faut déclarer une classe qui hérite de `nn.Module` et qui possède deux méthodes :\n",
        "\n",
        "\n",
        "\n",
        "*   `__init__(self, arguments)`\n",
        "*   `forward(self, arguments)` qui réalise une passe forward à l'aide des couches déclarées dans `__init__` et de fonctionnelles du module `F`\n",
        "\n",
        "Ainsi lorsque l'on définit un CNN, on va déclarer des couches de convolution qui sont des *modules*, à l'aide de `nn.Conv2d` et non la fonction `F.conv2d` qui est une fonctionnelle. Vous remarquerez l'usage d'une majuscule dans `nn.Conv2d`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB6Q9beegf5g"
      },
      "source": [
        "# Perceptron multi-couche \n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, num_hidden):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, num_hidden)\n",
        "        self.layer2 = nn.Linear(num_hidden, 10)\n",
        "        self.num_hidden = num_hidden\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 28 * 28) # flatten the image\n",
        "        activation1 = self.layer1(flattened)\n",
        "        activation1 = torch.relu(activation1)\n",
        "        activation2 = self.layer2(activation1)\n",
        "        return activation2\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=2,\n",
        "                               kernel_size=5)        \n",
        "        # pour info, on pourrait plus simplement écrire :\n",
        "        # self.conv1 = nn.Conv2d(1, 10, kernel_size=5, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=2,\n",
        "                               out_channels=4,\n",
        "                               kernel_size=5)\n",
        "        self.fc = nn.Linear(4 * 4 * 4, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 4 * 4 * 4)\n",
        "        return self.fc(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKzkbjebgf5i"
      },
      "source": [
        "Une façon d'évaluer la \"complexité\" ou la \"capacité\" d'un réseau\n",
        "est de regarder le nombre de paramètres :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8k4_bM3gf5k"
      },
      "source": [
        "def print_num_parameters(model):\n",
        "    print(\"Nombre de paramètres :\",\n",
        "          sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "print_num_parameters(CNN())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMTy9kl1gf5l"
      },
      "source": [
        "## Apprentissage\n",
        "\n",
        "On définit une fonction train qui s'occupe d'entraîner le modèle sur les données de train et qui mesure la loss sur le train, sur valid et les accuracies de \"temps en temps\", toutes les 50 itérations ici : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW0sBb_Cgf5m"
      },
      "source": [
        "def train(model, data, batch_size=64, weight_decay=0.0,\n",
        "          optimizer=\"sgd\", learning_rate=0.1, momentum=0.9,\n",
        "          data_shuffle=True, num_epochs=10):\n",
        "    # les données de train : un DataLoader qui fournit des minibatchs\n",
        "    train_loader = torch.utils.data.DataLoader(data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=data_shuffle)\n",
        "    # la loss \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # l'optimiseur\n",
        "    assert optimizer in (\"sgd\", \"adam\")\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(model.parameters(),\n",
        "                              lr=learning_rate,\n",
        "                              momentum=momentum,\n",
        "                              weight_decay=weight_decay)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(),\n",
        "                               lr=learning_rate,\n",
        "                               weight_decay=weight_decay)\n",
        "    # on track la learning curve avec des listes\n",
        "    iters, iters_acc, losses, train_acc, val_acc = [], [], [], [], []\n",
        "    # training\n",
        "    n = 0 # nombre d'iterations (pour faire des figures)\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "            if imgs.size()[0] < batch_size:\n",
        "                continue\n",
        "\n",
        "            model.train() # met le modèle en mode train\n",
        "            out = model(imgs)\n",
        "            loss = criterion(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "\n",
        "            if n % 50 == 0 :\n",
        "              train_acc.append(get_accuracy(model, train=True)) # compute training accuracy \n",
        "              val_acc.append(get_accuracy(model, train=False))  # compute validation accuracy\n",
        "              iters_acc.append(n)\n",
        "\n",
        "            n += 1\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Courbe d'apprentissage\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Courbe d'apprentissage\")\n",
        "    plt.plot(iters_acc, train_acc, label=\"Train\")\n",
        "    plt.plot(iters_acc, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Précision finale Train : {}\".format(train_acc[-1]))\n",
        "    print(\"Précision finale Valid : {}\".format(val_acc[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iccfHd1gf5n"
      },
      "source": [
        "Nous avons également besoin d'une fonction qui calcule la précision ou *accuracy*. \n",
        "\n",
        "Pour transformer les probabilités en une prédiction discrète, nous prendrons l'indice de la classe avec la probabilité la plus élevée.\n",
        "\n",
        "En raison de la façon dont softmax est calculée, cet indice \n",
        "est le même que celui pour lequel la pré-activation est la plus élevée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do6ZVJb7gf5o"
      },
      "source": [
        "def get_accuracy(model, train=False):\n",
        "    if train:\n",
        "        data = torch.utils.data.DataLoader(mnist_train, batch_size=256)\n",
        "    else:\n",
        "        data = torch.utils.data.DataLoader(mnist_val, batch_size=256)\n",
        "\n",
        "    model.eval() # met le modèle en mode test (inhibe le dropout par exemple)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in data:\n",
        "        output = model(imgs) # pas besoin de torch.softmax\n",
        "        pred = output.max(1, keepdim=True)[1] # retrouve l'indice de la log-proba maximale\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCztZyiOgf5o"
      },
      "source": [
        "Testons sur le CNN :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnwDggAUgf5p"
      },
      "source": [
        "model = CNN()\n",
        "train(model, mnist_train, batch_size=64, optimizer=\"sgd\", learning_rate=0.1,\n",
        "      momentum=0., num_epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O4svU2Lgf5r"
      },
      "source": [
        "### Rôle du shuffle\n",
        "\n",
        "Et si on désactive le `data_shuffle` ? C'est-à-dire, que se passe-t-il si nous utilisons les **mêmes mini-batchs** à travers toutes les epochs ? Pouvez-vous expliquer ce qui se passe dans les courbes d'apprentissage ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h2WE2W-gf5r"
      },
      "source": [
        "model = CNN()\n",
        "train(model, mnist_train, learning_rate=0.1, data_shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g-j0sMd-8oN"
      },
      "source": [
        "# Expériences avec le MLP\n",
        "\n",
        "Nous allons faire des expériences avec un MLP plutôt qu'avec le CNN car il est beaucoup plus rapide à entraîner (même sur CPU ici, car c'est un petit modèle)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p3XR8co_bFU"
      },
      "source": [
        "Définissons un MLP avec une couche cachée de 50 neurones :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkuB0CI-_fdb"
      },
      "source": [
        "model = MLP(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xff9BTKb_iFT"
      },
      "source": [
        "Combien de paramètres contient-il ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvK4R82-_kp8"
      },
      "source": [
        "print_num_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I0-Hm_9_Sds"
      },
      "source": [
        "Faisons un premier apprentissage, similaire au CNN : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4mxG6mj_Nsb"
      },
      "source": [
        "train(model, mnist_train, learning_rate=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQK1mTH2gf5s"
      },
      "source": [
        "## Momentum\n",
        "\n",
        "Nous allons principalement expérimenter avec le modèle `MLP(30)`, car c'est celui qui s'entraîne le plus rapidement.\n",
        "\n",
        "Nous mesurerons la rapidité de l'apprentissage du modèle en regardant les progrès réalisés dans les 3 premières épochs d'apprentissage. \n",
        "\n",
        "Quels résultats obtient-on sans utiliser momentum, avec un taux d'apprentissage de 0.1 ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KgMGXM6gf5t"
      },
      "source": [
        "model = MLP(30)\n",
        "train(model, mnist_train, learning_rate=0.1, momentum=0., num_epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXLykeqDgf5t"
      },
      "source": [
        "Avec un taux d'apprentissage et un momentum bien réglés, l'apprentissage peut aller plus vite.\n",
        "\n",
        "Remarque : nous avons dû essayer plusieurs paramètres avant d'en trouver un qui fonctionne bien. Nous vous encourageons à essayer différentes combinaisons de taux d'apprentissage et de momentum. Par exemple prendre un taux d'apprentissage de 0.1 et un momentum de 0.5 %."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-AL3tifgf5u"
      },
      "source": [
        "model = MLP(30)\n",
        "train(model, mnist_train, learning_rate=0.05, momentum=0.9, num_epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmKnd87Dgf5u"
      },
      "source": [
        "L'optimiseur Adam fonctionne bien et est d'ailleurs l'optimiseur le plus populaire actuellement.\n",
        "\n",
        "Adam requiert généralement un taux d'apprentissage plus faible : commencer par 0,001, puis augmenter/diminuer comme bon vous semble. Ici, 0.005 fonctionne bien."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2L7yeUTgf5v"
      },
      "source": [
        "model = MLP(30)\n",
        "train(model, mnist_train, optimizer=\"adam\", learning_rate=0.005, num_epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4feMgzavgf5x"
      },
      "source": [
        "## Batch Normalization (petit nom : batchnorm)\n",
        "\n",
        "Batch normalization peut beaucoup accélérer (et stabiliser) l'apprentissage !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJp0bV9lgf5y"
      },
      "source": [
        "class MLPBN(nn.Module):\n",
        "    def __init__(self, num_hidden):\n",
        "        super(MLPBN, self).__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, num_hidden)\n",
        "        self.bn = nn.BatchNorm1d(num_hidden)\n",
        "        self.layer2 = nn.Linear(num_hidden, 10)\n",
        "        self.num_hidden = num_hidden\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 28 * 28) # flatten \n",
        "        activation1 = self.layer1(flattened)\n",
        "        activation1 = torch.relu(activation1)\n",
        "        activation1 = self.bn(activation1)\n",
        "        activation2 = self.layer2(activation1)\n",
        "        return activation2\n",
        "\n",
        "mlp_bn = MLPBN(30)\n",
        "train(mlp_bn, mnist_train, optimizer=\"adam\", learning_rate=0.005, num_epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-q00TdJgf50"
      },
      "source": [
        "Il y a un débat pour savoir si la batch-norm doit être appliquée\n",
        "*avant* ou *après* l'activation. L'article original \n",
        "appliquait la normalisation avant l'activation de ReLU, mais l'application de la normalisation *après* la ReLU donne de meilleurs résultats dans la pratique. \n",
        "\n",
        "La raison pourrait être la suivante :\n",
        "\n",
        "1. Si nous appliquons la normalisation avant la ReLU, alors nous ignorons effectivement les biais des neurones, puisque les activations vont être centrées.\n",
        "\n",
        "2. Si nous appliquons la normalisation après ReLU, nous aurons des informations \n",
        "   positives et négatives qui seront transmises à la couche suivante.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gi1UDbMgf51"
      },
      "source": [
        "class MLPBNBeforeReLu(nn.Module):\n",
        "    def __init__(self, num_hidden):\n",
        "        super(MLPBNBeforeReLu, self).__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, num_hidden)\n",
        "        self.bn = nn.BatchNorm1d(num_hidden)\n",
        "        self.layer2 = nn.Linear(num_hidden, 10)\n",
        "        self.num_hidden = num_hidden\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 28 * 28) # flatten \n",
        "        activation1 = self.layer1(flattened)\n",
        "        activation1 = self.bn(activation1)\n",
        "        activation1 = torch.relu(activation1)\n",
        "        activation2 = self.layer2(activation1)\n",
        "        return activation2\n",
        "    \n",
        "train(MLPBNBeforeReLu(30), mnist_train, optimizer=\"adam\", learning_rate=0.005, num_epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9OIux0Rgf51"
      },
      "source": [
        "Batch norm est utilisée aussi dans les CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RI0o24Ngf52"
      },
      "source": [
        "class CNNBN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNBN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=4,\n",
        "                               kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(4) # nb de channels out\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=4,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=3,\n",
        "                               padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(8) # nb de channels out\n",
        "        self.fc = nn.Linear(8 * 7 * 7, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.bn2(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 8 * 7 * 7)\n",
        "        return self.fc(x)\n",
        "\n",
        "train(CNNBN(), mnist_train, optimizer=\"adam\", learning_rate=0.005, num_epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWgjaznfgf52"
      },
      "source": [
        "## Initialisation des poids à zéro : pas une bonne idée...\n",
        "\n",
        "Si nous initialisons les poids à zéro, le réseau sera coincé dans un point \"selle\" (*saddle point*). \n",
        "\n",
        "Étant donné que nous utilisons la descente de gradient stochastique, nous ne verrons que du bruit dans les courbes d'apprentissage et surtout aucun progrès."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws-Q7f5Agf53"
      },
      "source": [
        "model = MLP(30)\n",
        "for p in model.parameters():\n",
        "    nn.init.zeros_(p)\n",
        "train(model, mnist_train, optimizer=\"adam\", learning_rate=0.005, num_epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Un \"vrai\" réseau LeNet5"
      ],
      "metadata": {
        "id": "qVC67kgd-43e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Récupérer l'article LeNet5 sur moodle, implanter le réseau décrit dans l'article. Tester-le sur les données complètes MNIST. Peut-être activer le GPU de ce notebook si l'entraînement est trop long..."
      ],
      "metadata": {
        "id": "F4YMgVL2-fz1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXa-4UHuDLi6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}