{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HEb_8BjEJtn"
      },
      "source": [
        "# Mini MLP sur toy datasets\n",
        "\n",
        "L'objectif de ce premier TP est de reproduire la page Web démo :\n",
        "\n",
        "https://playground.tensorflow.org/\n",
        "\n",
        "Plus précisément, il s'agit de manipuler un mini réseau de neurones, comprenant une seule couche cachée avec peu de neurones, sur des données jouet en 2-d.\n",
        "\n",
        "Nous faisons ici de la classification binaire.\n",
        "\n",
        "**Il y a du code à compléter, indiqué par ?? ou par des questions**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v0C3KkSFXz70"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ilSh6e0gXkhN"
      },
      "outputs": [],
      "source": [
        "n_samples = 400\n",
        "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=0.05)\n",
        "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=0.05)\n",
        "blobs = datasets.make_blobs(n_samples=n_samples, centers=2, random_state=1)\n",
        "\n",
        "centers = [[1, 1], [1, -1], [-1, -1], [-1, 1]]\n",
        "blobs2 = datasets.make_blobs(n_samples=n_samples, centers=centers, cluster_std=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UFSwIgURbaYA"
      },
      "outputs": [],
      "source": [
        "colors = np.array( [\"#377eb8\", \"#ff7f00\", \"#4daf4a\", \"#f781bf\",] )\n",
        "\n",
        "# changer ici le jeu de données : noisy+circles, noisy_moons, etc.\n",
        "X, y = blobs2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(400, 2)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# blobs2 a quatre classes par construction, et on en veut que deux\n",
        "# Les autres jeux de données n'ont que deux classes donc \n",
        "# si commentez ces deux lignes qd vous utilisez un jeu autre que blobs2\n",
        "y[y==2]=0\n",
        "y[y==3]=1\n",
        "\n",
        "# on standardise les données (en général ça aide...)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "# on plotte\n",
        "plt.figure()\n",
        "\n",
        "plt.scatter(X,y, s=10, color=colors[y])\n",
        "\n",
        "plt.xlim(-2.5, 2.5)\n",
        "plt.ylim(-2.5, 2.5)\n",
        "# plt.xticks(())\n",
        "# plt.yticks(())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iywRpaDRlVR4"
      },
      "outputs": [],
      "source": [
        "# Ici on spitte les données en train et test.\n",
        "# Dans la vraie vie, il faudrait même trois sous-ensembles, train/valid/test...\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Transformer les tableaux numpy en tenseurs torch float :\n",
        "X_train = torch.??(X_train).to(torch.float)\n",
        "X_test = torch.??(X_test).to(torch.float)\n",
        "\n",
        "y_train = torch.??(y_train)\n",
        "y_test = torch.??(y_test)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHoqNp3Knbrw"
      },
      "outputs": [],
      "source": [
        "X_train[:2], y_train[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0XBSTmSN4eA"
      },
      "source": [
        "L'architecture de notre premier réseau de neurones va être définie dans la prochaine cellule. \n",
        "\n",
        "Nous allons mettre en oeuvre un mini réseau tel que representé dans cette figure, avec l'architecture suivante : \n",
        "\n",
        "*   une seule couche cachée linéaire à 4 neurones,\n",
        "*   suivie d'une fonction d'activation tanh, \n",
        "*   puis d'une couche de sortie linéaire à deux neurones. \n",
        "\n",
        "Nous n'ajoutons pas de fonction d'activation à la couche de sortie. \n",
        "\n",
        "Vous remarquez que nous faisons une tâche de classification binaire (deux classes à distinguer) mais en utilisant deux neurones de sortie au lieu d'un seul qui suffirait. En pratique, ça peut être un peu plus facile à entraîner d'utiliser deux neurones, et donc on résoud le problème binaire par un modèle de classification \"multi-classe\" à deux classes. La fonction de loss sera à choisir en conséquence plus loin...\n",
        " \n",
        " <img src=\"https://www.irit.fr/~Thomas.Pellegrini/ens/M1ML1/mini_nn.png\" alt=\"image nn\"  width=\"400\" height=\"320\"> \n",
        "\n",
        "La déclaration des deux couches linéaires est à faire dans la méthode ```__init__()```. Consultez la documentation de Pytorch et du module ```torch.nn``` en particulier pour vous aider pour la déclaration de couches :\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "Pour les fonctions mathématiques comme ```tanh```, il y a plusieurs façons de faire, mais la plus simple à notre avis, est d'utiliser celles directement accessibles dans le module ```torch```, voir :\n",
        "\n",
        "https://pytorch.org/docs/stable/torch.html#math-operations\n",
        "\n",
        "\n",
        "Dans la fonction ```forward()```, vous appliquez les couches et la fonction d'activation dans l'ordre sur un mini-batch de features  ```x``` qui devient la variable ```out```.\n",
        "\n",
        "Remarques : \n",
        "\n",
        "\n",
        "1.   tous les modèles que vous allez définir dans les TP comportent ces deux méthodes, ```__init__()``` et ```forward()```.\n",
        "2.   un modèle est déclaré sous forme d'une classe qui hérite de ```nn.Module```.\n",
        "Cela permet d'appeler le modèle facilement sur des données par la suite, en écrivant : ```output = model(data)```\n",
        "3.   À noter qu'il ne faut surtout pas écrire : \n",
        "```output = model.forward(data)``` \n",
        "mais ```output = model(data)```\n",
        "\n",
        "car une fonction ```__call__()``` est automatiquement appelée, qui fait \n",
        "des allocations mémoire qui vont bien automatiquement pour nous. Cette méthode appelle ```forward()```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMiDwJr1cc0s"
      },
      "outputs": [],
      "source": [
        "# \n",
        "class MLP(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_hidden=4):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = ??\n",
        "        self.layer2 = ??\n",
        "        self.num_hidden = num_hidden\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = ??\n",
        "        out = ??\n",
        "        out = ??\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56xw3g4lhx9z"
      },
      "outputs": [],
      "source": [
        "# On instancie le modèle et on regarde combien de paramètres il a \n",
        "\n",
        "model = MLP()\n",
        "\n",
        "def print_num_parameters(model):\n",
        "    print(\"Nombre de paramètres :\",\n",
        "          sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "print_num_parameters(model)\n",
        "\n",
        "# Ce nombre vous semble-t-il logique ? Vérifier sur le papier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hNRVYVOIX8z"
      },
      "source": [
        "La prochaine cellule réalise l'entraînement d'un modèle que l'on instancie à nouveau, pour être sûr de repartir sur un nouveau modèle à chaque fois que l'on exécute cette cellule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gdOfGWSiSZT"
      },
      "outputs": [],
      "source": [
        "model = MLP()\n",
        "\n",
        "learning_rate=??\n",
        "\n",
        "\n",
        "nb_epochs = 25\n",
        "bs = 20\n",
        "\n",
        "criterion = nn.??\n",
        "optimizer = optim.SGD(??,\n",
        "                      lr=learning_rate,\n",
        "                      momentum=0.9)\n",
        "\n",
        "# Essayer Adam si vous le souhaitez :\n",
        "# optimizer = optim.Adam(model.parameters(),\n",
        "#                       lr=learning_rate)\n",
        "\n",
        "n = 0 # nombre d'iterations (pour faire des figures)\n",
        "iters = []\n",
        "losses = []\n",
        "test_losses, test_acc = [], []\n",
        "test_iters = []\n",
        "\n",
        "for epoch in range(1, nb_epochs+1):\n",
        "    \n",
        "    # shuffle\n",
        "    idx = torch.randperm(X_train.size(0))\n",
        "    X_train_ = X_train[idx]\n",
        "    y_train_ = y_train[idx]\n",
        "    # print(len(X_train)//bs)\n",
        "\n",
        "    model.train() # met le modèle en mode train\n",
        "\n",
        "    for i in range(0, len(X_train)//bs):\n",
        "        X_train_batch = X_train_[i*bs:(i+1)*bs]\n",
        "        y_train_batch = y_train_[i*bs:(i+1)*bs]\n",
        "        # print(X_train_batch.shape, y_train_batch.shape)\n",
        "        \n",
        "        out = model(X_train_batch)\n",
        "        loss = criterion(out, y_train_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        iters.append(n)\n",
        "        losses.append(float(loss)/bs)\n",
        "        n += 1\n",
        "\n",
        "    if (epoch-1) % 10 == 0 or epoch==nb_epochs:\n",
        "      model.eval() # met le modèle en mode eval\n",
        "      # à quoi sert cette ligne ?\n",
        "      with torch.no_grad():\n",
        "        out = model(X_test)\n",
        "        loss = criterion(out, y_test)\n",
        "        test_losses.append(loss)\n",
        "        \n",
        "        pred = out.max(1, keepdim=True)[1] # retrouve l'indice de la log-proba maximale\n",
        "        correct = pred.eq(y_test.view_as(pred)).sum().item()\n",
        "        total = y_test.size(0)\n",
        "        test_acc.append(correct/total*100.)\n",
        "        test_iters.append((epoch-1)*len(X_train)//bs)\n",
        "        print(\"epoch %d --- acc = %.2f\"%(epoch, test_acc[-1]))\n",
        "\n",
        "# print(iters)\n",
        "# plotting\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.title(\"Courbe d'apprentissage\")\n",
        "plt.plot(iters, losses, label=\"Train\")\n",
        "plt.plot(test_iters, test_losses, label=\"Test\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw5-b2hFKAy_"
      },
      "source": [
        "## Graphique 2-d Heat map des prédictions du réseau\n",
        "\n",
        "Écrire la fonction suivante ```fun()``` qui réalise une passe foward de ```data``` au travers du réseau ```model```donnés en arguments.\n",
        "\n",
        "Cette fonction renvoie la prédiction de l'un des deux neurones de sortie de votre choix (choix arbitraire ici, on n'a pas défini quelle classe est la classe positive ou négative).\n",
        "\n",
        "Veuillez normaliser les sorties des neurones par une ```softmax``` avant d'en sélectionner une seule.\n",
        "\n",
        "L'output doit être converti en tableau ```numpy``` avant d' être retournée.\n",
        "\n",
        "*   à quoi sert la ligne \"with torch.no_grad():\" ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szLTR_zzmT4K"
      },
      "outputs": [],
      "source": [
        "def fun(model, data):\n",
        "    model.eval() # met le modèle en mode eval\n",
        "    with torch.no_grad():\n",
        "      out = ??\n",
        "    return out.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-Rs_BO5q23W"
      },
      "source": [
        "Cette prochaine cellule trace la carte de chaleur (heat map) des prédictions du réseau en deux dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oya0sOR3X6Bf"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = plt.figure(figsize=(6,6))\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], s=10, color=colors[y_test])\n",
        "\n",
        "plt.xlim(-2.5, 2.5)\n",
        "plt.ylim(-2.5, 2.5)\n",
        "\n",
        "x1 = x2 = np.arange(-2.5, 2.5, 0.1)\n",
        "\n",
        "# utiliser la fonction meshgrid de numpy :\n",
        "X1, X2 = ??\n",
        "\n",
        "output = np.array([fun(model, torch.from_numpy(np.array([x1, x2])).to(torch.float)) for x1, x2 in zip(np.ravel(X1), np.ravel(X2))])\n",
        "print(output.shape, output)\n",
        "\n",
        "output = output.reshape(X1.shape)\n",
        "\n",
        "plt.pcolormesh(X1, X2, output, cmap=cm.coolwarm, alpha=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76H090fzJN3O"
      },
      "source": [
        "## Graphique 3-d interactif avec le module plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-V3q3fQzpsT"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "fig = go.Figure(data=[go.Surface(x=X1, y=X2, z=output, opacity=0.7)])\n",
        "\n",
        "# Les points de dataset :\n",
        "fig.add_scatter3d(x=X_test[:, 0],\n",
        "                  y=X_test[:, 1],\n",
        "                  z=y_test, \n",
        "                  marker=dict(\n",
        "                      size=4,\n",
        "                      color=colors[y_test],                # set color to an array/list of desired values\n",
        "                      # colorscale='Viridis',   # choose a colorscale\n",
        "                      opacity=0.8\n",
        "    ),\n",
        "                  mode = \"markers\") # Important pour ne pas avoir des lignes entre les différents points.\n",
        "\n",
        "# On affiche la figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vIzhmzyKMvW"
      },
      "source": [
        "## À faire\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Ré-exécuter plusieurs fois l'entraînement du réseau et faire les graphiques. Que constatez-vous ?\n",
        "*   Jouer avec le learning rate et l'optimiseur\n",
        "*   Changer la fonction d'activation\n",
        "*   Baisser ou augmenter le nb de neurones de la couche cachée\n",
        "*   Refaire les expériences avec un autre jeu de données proposé\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtU3_vKhzpsU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVPQjl44zqW7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ML1_TP1_toy_NN_sujet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
